# **CLAUDE.md - Dashboard Projekt** 
*Optimiert fÃ¼r autonome Entwicklung*

## ğŸ§  **KRITISCHES DENKEN & RÃœCKFRAGEN**
**Du sollst KRITISCH HINTERFRAGEN und RÃœCKFRAGEN stellen, um die bestmÃ¶glichen Ergebnisse zu erzielen:**

- âš¡ **Hinterfrage Anforderungen:** Ist das wirklich die beste LÃ¶sung?
- ğŸ¯ **Bewerte Alternativen:** Gibt es bessere/einfachere Wege?
- ğŸ” **Analysiere Trade-offs:** Performance vs. KomplexitÃ¤t vs. Wartbarkeit
- ğŸ’¡ **Stelle RÃ¼ckfragen:** Bei Unklarheiten â†’ nachfragen statt raten
- ğŸ—ï¸ **PrÃ¼fe Architektur:** Passt das zur bestehenden Codebase?
- ğŸ“Š **Validiere Business-Value:** LÃ¶st das echte Probleme?

**REGEL:** Bevor du implementierst â†’ erklÃ¤re deine Ãœberlegungen und hole Feedback ein!

## ğŸ“ **BEST PRACTICES**
**Arbeite nach Industry Best Practices, wenn sinnvoll:**
- ğŸ—ï¸ **Strategic Testing:** Focus on business-critical areas, not comprehensive coverage
- ğŸ“¦ **SOLID Principles:** Single Responsibility, DRY, KISS
- ğŸ”’ **Security First:** OWASP Top 10, Zero Trust
- ğŸ¯ **Performance:** Core Web Vitals, Bundle Size
- â™¿ **Accessibility:** WCAG 2.1 AA Standards
- ğŸ“š **Clean Code:** Lesbar > Clever

**ABER:** Best Practice nur wenn es zum Projekt passt - Pragmatismus > Dogma!

## ğŸ¯ **PROJEKTMISSION**
Erstelle ein **SaaS Analytics Dashboard** mit externen API-Integrationen. Du arbeitest **autonom** mit regelmÃ¤ÃŸigen Checkpoints.

---

## ğŸ¤ **ARBEITSWEISE**

### **1. Standard-Workflow**
```bash
VERSTEHEN â†’ PLANEN â†’ IMPLEMENTIEREN â†’ VALIDIEREN
```

### **ğŸ›‘ KEINE QUICK FIXES**
- **VollstÃ¤ndige LÃ¶sungen** statt Symptom-Behandlung
- **Root Cause Analysis** vor jeder Implementation
- Bei Problemen â†’ **Verstehen, dann lÃ¶sen**

### **ğŸ”„ TEST & ROLLBACK PRINZIP**
- **LÃ¶sung testen** â†’ Funktioniert nicht â†’ **VOLLSTÃ„NDIGER ROLLBACK**
- **Ausgangspunkt wiederherstellen** vor nÃ¤chstem Versuch
- **Keine akkumulierten Workarounds**

### **âœ… COMPLETE FEATURES ONLY**
- **Keine Platzhalter** oder "TODO" Kommentare
- **Aufbauende Implementation** - jeder Schritt funktioniert vollstÃ¤ndig
- **Ein Feature = Ein funktionierender Baustein**

### **ğŸ§ª COMPLEXITY-BASED TASK STRATEGY**
**Basiert auf erfolgreicher DI-Migration: 4 failing â†’ 107 passing tests (100% Erfolg)**

#### **ğŸ“Š COMPLEXITY INDICATORS & DECISION FRAMEWORK**
```bash
ğŸŸ¢ SIMPLE (1-3 files, <2h)     â†’ Direct Implementation
ğŸŸ¡ MEDIUM (4-10 files, 2-8h)   â†’ 2-3 Phase Approach  
ğŸ”´ COMPLEX (10+ files, >8h)    â†’ 4-6 Phase Test-Driven
âš« MEGA (system-wide, days)    â†’ 6+ Phases + User Checkpoints
```

**Risk Indicators (upgrade complexity level):**
- Touching core authentication/authorization
- Database schema changes
- Breaking API changes
- Cross-component integrations
- Production-critical features

#### **ğŸ“‹ PHASE TEMPLATES**

**ğŸŸ¡ MEDIUM TASK (2-3 Phases):**
```
Phase 1: Core Implementation (60% effort)
â”œâ”€ npm test + npx tsc --noEmit
â”œâ”€ Basic functionality working
â””â”€ Main happy path covered

Phase 2: Integration & Refinement (30% effort)  
â”œâ”€ npm run lint + docker restart
â”œâ”€ Error handling + edge cases
â””â”€ Browser validation

Phase 3: Finalization (10% effort)
â”œâ”€ Documentation + cleanup
â””â”€ Final validation
```

**ğŸ”´ COMPLEX TASK (4-6 Phases):**
```
Phase 1: Foundation/Interface (20% effort)
â”œâ”€ Test-driven interface design
â”œâ”€ npm test (new tests pass)
â””â”€ Clear contracts established

Phase 2: Core Logic Implementation (40% effort)
â”œâ”€ Main functionality 
â”œâ”€ npm test + TypeScript validation
â””â”€ Integration points working

Phase 3: Dependencies & Integration (25% effort)
â”œâ”€ Connect to existing systems
â”œâ”€ npm test + lint + docker restart
â””â”€ End-to-end flow working

Phase 4: Edge Cases & Error Handling (10% effort)
â”œâ”€ Error scenarios + production safety
â”œâ”€ Comprehensive test validation
â””â”€ Browser/manual testing

Phase 5: Finalization & Documentation (5% effort)
â”œâ”€ Code cleanup + documentation
â””â”€ Final production readiness check
```

#### **âš–ï¸ SMART TESTING BALANCE**

**âœ… ALWAYS TEST & VALIDATE:**
- **Integration boundaries** (APIs, contexts, external services)
- **Complex business logic** (calculations, transformations, algorithms)
- **Error handling** (try/catch, edge cases, fallbacks)
- **Critical user flows** (auth, payments, data integrity)
- **Cross-component communication** (props, events, state)

**âŒ SKIP TESTING (Efficiency):**
- Trivial constants & configuration objects
- Basic CRUD without business logic
- Simple prop passing & presentation components
- Auto-generated code & type definitions
- Single-line utilities & formatters

#### **ğŸš€ VALIDATION EFFICIENCY MATRIX**

**Per Phase Validation Level:**
```
Simple Task    â†’ npm test + TypeScript
Medium Phase 1 â†’ npm test + TypeScript  
Medium Phase 2 â†’ + npm run lint + docker restart
Medium Phase 3 â†’ + browser validation

Complex Phase 1 â†’ npm test + TypeScript (interface focus)
Complex Phase 2 â†’ + integration tests
Complex Phase 3 â†’ + lint + docker + browser testing  
Complex Phase 4 â†’ + error scenario testing
Complex Phase 5 â†’ + production readiness validation
```

**ğŸ¯ Parallel Validation (Efficiency):**
```bash
# Single command for speed
npm test & npx tsc --noEmit & npm run lint & wait
./scripts/quick-restart.sh & browser-check & wait
```

#### **âœ… SUCCESS CRITERIA PER PHASE**
- **Code Quality:** All validations pass (test/lint/TypeScript)
- **Functionality:** Phase objectives 100% met
- **Integration:** Connecting systems work flawlessly  
- **No Regression:** Existing functionality unchanged
- **Documentation:** Complex decisions explained

**ğŸ›‘ PHASE FAILURE = FULL ROLLBACK**
- Restore previous working state completely
- Analyze root cause before retry
- Adjust approach if needed

### **ğŸ“Š DEBUGGING DASHBOARD UPDATE (MANDATORY - AUTOMATISIERT)**
- **Nach JEDER Task-Completion**: Automatisch `./scripts/collect-real-metrics.sh` ausfÃ¼hren
- **Nach Code-Ã„nderungen**: Dashboard mit aktuellen Metriken updaten
- **Nach Feature-Implementation**: Achievement-Liste in real-metrics.json erweitern
- **AKTUELLER STATUS**: 
  - âŒ **85 TypeScript Errors** (kritisch)
  - âŒ **19 ESLint Errors** (hoch)  
  - âš ï¸ **17 ESLint Warnings** (medium)
  - **Overall Score: 66/100** (needs improvement)
- **WORKFLOW**: Task Start â†’ Code â†’ Test â†’ `./scripts/collect-real-metrics.sh` â†’ Commit
- **ZIEL**: Alle Errors auf 0 reduzieren fÃ¼r solid foundation vor Chart.js Integration

### **ğŸ”§ HYBRID DEVELOPMENT WORKFLOW**

#### **âš¡ QUICK DEV CHECKS (npm-basiert, fÃ¼r Speed):**
- âœ… **npm run lint** - ESLint Validierung
- âœ… **npx tsc --noEmit** - TypeScript Compilation Check
- âœ… **Quick syntax/type checks** fÃ¼r Development Feedback

#### **ğŸ³ INTEGRATION & DEPLOYMENT (Docker-basiert, fÃ¼r Konsistenz):**
- âœ… **./scripts/quick-restart.sh** - Container rebuild & restart
- âœ… **docker logs** - Runtime error checking
- âœ… **Full application testing** in production-like environment

#### **ğŸ“‹ COMPLETE VALIDATION WORKFLOW:**
```bash
# Nach Code-Ã„nderungen:
# 1. SCHNELLE CHECKS (Host):
npm run lint                    # ESLint errors
npx tsc --noEmit               # TypeScript compilation

# 2. INTEGRATION TEST (Docker):
./scripts/quick-restart.sh     # Container rebuild
docker logs daten-see-app      # Runtime validation

# 3. COMMIT nur wenn beide Stufen erfolgreich
git add . && git commit -m "fix: description"
```

#### **ğŸ”„ RESTART-TRIGGERING EVENTS:**
- **IMMER restart**: `package.json` changes, new dependencies, Docker config
- **NIEMALS restart**: Source code changes (TS/TSX/CSS) â†’ Hot reload genÃ¼gt
- **CONDITIONAL restart**: Environment variables, config files

#### **ğŸ› ï¸ DOCKER COMMAND REFERENCE:**
```bash
# âœ… VALIDATION (inside container)
docker exec $CONTAINER_ID npm run lint -- --fix
docker exec $CONTAINER_ID npm run build         # Production build test
docker exec $CONTAINER_ID npm run test:coverage # Coverage report

# âœ… DEBUGGING
./scripts/docker-dev.sh logs    # Application logs
./scripts/docker-dev.sh shell   # Container shell access
./scripts/docker-dev.sh stats   # Performance monitoring

# âœ… MANAGEMENT  
./scripts/quick-restart.sh       # Standard restart
./scripts/docker-dev.sh rebuild  # Force rebuild (issues)
```

#### **ğŸš¨ ABSOLUTE VERBOTE (Host Commands):**
```bash
# âŒ NEVER ON HOST:
npm run dev
npm run build  
npm run lint
npm test
npx tsc --noEmit
# â†’ Use: docker exec $CONTAINER_ID [command]
```

### **ğŸ“‹ ROADMAP WORKFLOW (MANDATORY)**
- **IMMER der Roadmap folgen**: Niemals Tasks Ã¼berspringen oder eigene Reihenfolge wÃ¤hlen
- **Task-Batch laden**: Bei Start einer Haupttask (z.B. 1.7) ALLE Subtasks (1.7.1, 1.7.2, etc.) in TodoWrite laden
- **TodoWrite als Arbeitsliste**: Nutze TodoWrite als primÃ¤ren Zwischenspeicher fÃ¼r alle anstehenden Subtasks
- **Sequentielle Bearbeitung**: Task X.Y.Z vollstÃ¤ndig abschlieÃŸen BEVOR X.Y.(Z+1) beginnt

#### **HYBRID TEST & COMMIT WORKFLOW:**
- **Nach JEDER Subtask (z.B. 1.7.6.1):**
  1. Lokale Tests: `npm test` (schnell)
  2. Type-Check: `npm run typecheck` (schnell)
  3. Bei Fehler â†’ sofort fixen
  4. TodoWrite Status update
  
- **Nach AUFGABEN-BATCH (z.B. alle 1.7.6):**
  1. Lint Check: `npm run lint`
  2. Docker restart: `./scripts/quick-restart.sh`
  3. VollstÃ¤ndige Tests im Browser
  4. Git commit mit Summary aller Subtasks
  5. In IMPLEMENTATION-ROADMAP.md alle Subtasks abhaken: `[ ]` â†’ `[x]` + `âœ… **COMPLETED**`
  6. Git push
  
- **REGEL**: Code-QualitÃ¤t durch kontinuierliche Tests, Effizienz durch Batch-Commits

### **âš ï¸ ABWEICHUNG VOM PLAN (MANDATORY)**
- **NIEMALS eigenmÃ¤chtig vom geplanten Vorgehen abweichen**
- **VOR jeder Abweichung**: User mit bewerteten Alternativen informieren
- **Format**: Problem â†’ Alternative 1 (Pro/Contra/Aufwand) â†’ Alternative 2 â†’ Alternative 3 â†’ Empfehlung
- **Gemeinsame Entscheidung**: User entscheidet welche Alternative umgesetzt wird
- **REGEL**: Lieber nachfragen als eigenstÃ¤ndig "optimieren"

### **2. COMPLEXITY-BASED TASK STRATEGY**

#### **ğŸ“Š TASK COMPLEXITY DECISION FRAMEWORK**

**ğŸ¯ SUCCESS BASELINE:** Dependency injection migration (4 failing â†’ 107 passing tests, zero regressions)

##### **COMPLEXITY INDICATORS (Choose Approach Based On):**

**ğŸŸ¢ SIMPLE TASKS â†’ Direct Implementation**
- **Criteria:** 1-3 files affected, isolated changes, no critical dependencies
- **Examples:** UI tweaks, single component updates, documentation changes
- **Validation:** Standard quality gates only
- **Time:** < 30 minutes

**ğŸŸ¡ MEDIUM TASKS â†’ 2-3 Phase Approach**
- **Criteria:** 4-10 files affected, some cross-dependencies, business logic changes
- **Examples:** New feature with tests, API endpoint + UI integration, refactoring
- **Validation:** Tests after each phase + final integration check
- **Time:** 30-90 minutes

**ğŸ”´ COMPLEX TASKS â†’ 4-6 Phase Incremental (TEST-DRIVEN)**
- **Criteria:** 10+ files affected, system-wide impact, critical path modifications
- **Examples:** Architecture changes, large refactors, dependency migrations
- **Risk Factors:** Production impact, data integrity, security implications
- **Validation:** Full test suite after each phase
- **Time:** 2+ hours

**âš« MEGA TASKS â†’ 6+ Phases with Checkpoints**
- **Criteria:** Cross-system changes, major version upgrades, complete rewrites
- **Examples:** Framework migrations, database schema changes, deployment pipeline
- **Validation:** User checkpoints between major phases
- **Time:** Multiple sessions

### **ğŸš€ SUSTAINABLE CODE QUALITY & ULTRA THINK INTEGRATION**
**Basiert auf User-Feedback: "Keine quickfixes, nachhaltige LÃ¶sungen"**

#### **âŒ ANTI-PATTERNS (ABSOLUT VERBOTEN):**
```typescript
// âŒ NIEMALS: ESLint Suppressions
// eslint-disable-next-line @typescript-eslint/no-unused-vars
// eslint-disable-next-line react-hooks/exhaustive-deps

// âŒ NIEMALS: Quick Type Workarounds  
const data = response as any;

// âŒ NIEMALS: Error Hiding
try { riskyOperation(); } catch { /* ignore */ }
```

#### **âœ… SUSTAINABLE SOLUTIONS:**
```typescript
// âœ… PROPER: Refactor unused vars
function processData({ userId, email }: { userId: string; email: string; unusedField?: string }) {
  return { userId, email }; // Only use what you need
}

// âœ… PROPER: Fix hook dependencies  
const login = useCallback(async (credentials) => {
  await authManager.login(credentials);
}, [authManager]); // Include dependencies

// âœ… PROPER: Type properly
interface ApiResponse {
  data: UserData[];
  meta: PaginationMeta;
}
const response: ApiResponse = await api.get('/users');
```

#### **ğŸ§  ULTRA THINK & SUBAGENTS INTEGRATION**

##### **WHEN TO USE ULTRA THINK:**
**ğŸ¯ TRIGGER CONDITIONS:**
- ESLint/TypeScript errors > 10 (complex dependencies)
- Architecture decisions affecting >5 files
- User explicitly requests deep analysis ("ultra think")
- Production-critical changes (auth, payments, data)
- Complex refactoring with risk factors
- When multiple viable approaches exist

##### **ULTRA THINK PROCESS:**
**ğŸ” ANALYSIS FRAMEWORK:**
```
1. PROBLEM DECOMPOSITION
   â”œâ”€ Root cause analysis
   â”œâ”€ Dependencies mapping  
   â”œâ”€ Risk assessment
   â””â”€ Impact evaluation

2. SOLUTION EXPLORATION
   â”œâ”€ Option A: [Approach + Pros/Cons]
   â”œâ”€ Option B: [Approach + Pros/Cons]
   â”œâ”€ Option C: [Approach + Pros/Cons]
   â””â”€ RECOMMENDATION with reasoning

3. IMPLEMENTATION STRATEGY
   â”œâ”€ Phase breakdown
   â”œâ”€ Testing approach
   â”œâ”€ Rollback plan
   â””â”€ Success metrics
```

##### **SUBAGENTS UTILIZATION:**
**ğŸ¤– WHEN TO DEPLOY SUBAGENTS:**
- **Research Tasks:** "Search for all X patterns in codebase"
- **Analysis Tasks:** "Identify all dependencies of component Y"
- **Validation Tasks:** "Check test coverage for module Z"
- **Documentation Tasks:** "Generate comprehensive API docs"

**âš¡ SUBAGENT WORKFLOW:**
```bash
1. COMPLEX TASK DETECTED
   â†“
2. EVALUATE: Would subagents help?
   â”œâ”€ Multiple search/analysis tasks?
   â”œâ”€ Parallel information gathering needed?
   â””â”€ Large codebase exploration required?
   â†“
3. PROPOSAL: "I suggest using subagents for..."
   â†“
4. USER APPROVAL
   â†“
5. DEPLOY AGENTS + SYNTHESIZE RESULTS
```

#### **ğŸ¯ QUALITY DECISION MATRIX**

**WHEN TO PROPOSE ULTRA THINK:**
| Complexity | Files Affected | Risk Level | Action |
|------------|---------------|------------|--------|
| ğŸŸ¢ Simple  | 1-3          | Low        | Direct fix |
| ğŸŸ¡ Medium  | 4-10         | Medium     | Consider ultra think |
| ğŸ”´ Complex | 10+          | High       | **PROPOSE ultra think** |
| âš« Mega    | System-wide  | Critical   | **MANDATORY ultra think** |

**TRIGGER PHRASES:**
- User: "bewerte die Optionen" â†’ **Ultra think required**
- User: "tiefe Analyse" â†’ **Ultra think required**  
- User: "verschiedene Alternativen" â†’ **Ultra think required**
- Multiple ESLint errors â†’ **Consider ultra think**
- Architecture changes â†’ **Consider ultra think**

#### **ğŸ”„ PHASE STRUCTURE TEMPLATES**

##### **Medium Task Template (2-3 Phases):**
```bash
Phase 1: Core Implementation (60% effort)
  â”œâ”€â”€ npm test (unit tests)
  â””â”€â”€ npx tsc --noEmit (type check)

Phase 2: Integration & Edge Cases (30% effort)  
  â”œâ”€â”€ npm run lint
  â”œâ”€â”€ ./scripts/quick-restart.sh
  â””â”€â”€ Browser testing

Phase 3: Finalization & Polish (10% effort)
  â”œâ”€â”€ Documentation updates
  â”œâ”€â”€ Final validation
  â””â”€â”€ Git commit
```

##### **Complex Task Template (4-6 Phases):**
```bash
Phase 1: Foundation Setup (20% effort)
  â”œâ”€â”€ Types & interfaces
  â”œâ”€â”€ npm test (affected tests pass)
  â””â”€â”€ TypeScript compilation

Phase 2: Core Logic Implementation (40% effort)
  â”œâ”€â”€ Main business logic
  â”œâ”€â”€ npm test (full test suite)
  â””â”€â”€ Integration point validation

Phase 3: Dependencies & Integrations (25% effort)
  â”œâ”€â”€ Cross-component connections  
  â”œâ”€â”€ npm test + npm run lint
  â””â”€â”€ ./scripts/quick-restart.sh

Phase 4: Edge Cases & Error Handling (10% effort)
  â”œâ”€â”€ Error boundaries & fallbacks
  â”œâ”€â”€ Full validation workflow
  â””â”€â”€ Browser testing

Phase 5: Finalization & Cleanup (5% effort)
  â”œâ”€â”€ Code cleanup & optimization
  â”œâ”€â”€ Documentation updates
  â””â”€â”€ Final commit with summary
```

#### **âš–ï¸ VALIDATION BALANCE STRATEGY**

##### **ğŸ¯ LEAN TESTING STRATEGY (Quality over Quantity):**

**âœ… ALWAYS TEST:**
- Integration boundaries & API connections
- Complex business logic & calculations  
- Error handling & edge cases
- Critical user flows & data integrity
- Cross-component dependencies

**âš ï¸ SELECTIVE TESTING:**
- Simple getters/setters (test only if complex logic)
- UI components (snapshot tests for complex ones)
- Configuration files (test critical paths only)
- Pure utility functions (test complex algorithms only)

**âŒ SKIP TESTING:**
- Trivial constants & enums
- Basic CRUD operations without business logic
- Simple prop passing in React components
- Auto-generated code & type definitions

##### **ğŸ“ˆ VALIDATION EFFICIENCY MATRIX:**

| Phase Type | Unit Tests | Integration | E2E | Browser Check |
|------------|------------|-------------|-----|---------------|
| Foundation | âœ… Critical only | âŒ | âŒ | âŒ |
| Core Logic | âœ… All affected | âœ… Key flows | âŒ | âŒ |
| Integration | âœ… Full suite | âœ… All paths | âš ï¸ Smoke test | âœ… Manual |
| Finalization | âœ… Full suite | âœ… All paths | âœ… Critical flows | âœ… Complete |

#### **ğŸš€ EFFICIENCY MAXIMIZERS**

##### **PARALLEL VALIDATION COMMANDS:**
```bash
# Run simultaneously for speed:
npm test & npx tsc --noEmit & npm run lint &
wait  # Wait for all to complete
```

##### **QUICK DECISION CRITERIA:**
- **Files affected < 5** â†’ Direct implementation
- **Tests currently failing** â†’ Always use incremental approach  
- **Production deadline pressure** â†’ Medium approach with focused testing
- **New architecture/patterns** â†’ Complex approach with full validation
- **User explicitly requests "quick fix"** â†’ Document risks, proceed direct

##### **SUCCESS CRITERIA PER PHASE:**
- **Green Tests:** All existing tests pass
- **Clean Compilation:** No TypeScript errors
- **Lint Compliance:** No new warnings
- **Browser Functionality:** Feature works as expected
- **Performance Baseline:** No regression in load times

#### **ğŸ“‹ DECISION WORKFLOW:**

```bash
1. ANALYZE TASK COMPLEXITY
   â”œâ”€â”€ Count affected files
   â”œâ”€â”€ Identify critical dependencies  
   â”œâ”€â”€ Assess risk factors
   â””â”€â”€ Estimate effort

2. SELECT APPROACH
   â”œâ”€â”€ Simple â†’ Direct implementation
   â”œâ”€â”€ Medium â†’ 2-3 phases
   â”œâ”€â”€ Complex â†’ 4-6 phases  
   â””â”€â”€ Mega â†’ Checkpoint with user

3. EXECUTE WITH VALIDATION
   â”œâ”€â”€ Run appropriate tests per phase
   â”œâ”€â”€ Validate integration points
   â”œâ”€â”€ Check for regressions
   â””â”€â”€ Document any deviations

4. FINALIZE & COMMIT
   â”œâ”€â”€ Complete validation workflow
   â”œâ”€â”€ Update documentation
   â”œâ”€â”€ Commit with clear summary
   â””â”€â”€ Update TodoWrite status
```

### **3. Autonomie-Level**
**ErklÃ¤re erst, code dann:**
**Du schlÃ¤gst vor, bewertest und begrÃ¼ndest die Optionen:** das gilt fÃ¼r alle Schritte insbesondere Implementation-Details, Tool-Auswahl, Code-Struktur, Feature-Requirements, UI/UX-Ã„nderungen, Business-Logik, Architektur-Entscheidungen, Performance-Trade-offs
- Stichpunkte **vor** jeder Implementation
- Bei Unklarheiten deinerseits â†’ Nachfragen statt Raten
- **User entscheidet** ob Ã„nderungen notwendig sind und gibt es dann frei
- Ein Feature = Ein Commit

---

## âœ… **QUALITÃ„TS-GATES**

### **Automatische Validierung:**
- [ ] TypeScript kompiliert ohne Errors
- [ ] Tests laufen durch (`npm test`)
- [ ] ESLint/Prettier ohne Warnings
- [ ] Docker Container startet erfolgreich

### **Manuelle Validierung:**
- [ ] Feature funktioniert im Browser
- [ ] Responsive Design auf Mobile
- [ ] Error States zeigen sinnvolle Messages
- [ ] Performance ist akzeptabel (< 3s Load)

---

## ğŸ› ï¸ **IMPLEMENTATION-STANDARDS**

### **Code-QualitÃ¤t:**
```typescript
// âœ… GOOD: Klar, typisiert, testbar
// Async function mit expliziten Types fÃ¼r Parameter und Return-Value
export async function fetchUserData(userId: string): Promise<UserData> {
  try {
    // HTTP GET mit Template-String (sicher gegen injection)
    const response = await api.get(`/users/${userId}`);
    // Zod validation fÃ¼r Runtime-Type-Safety
    return UserDataSchema.parse(response.data);
  } catch (error) {
    // Structured logging mit Context fÃ¼r debugging
    logger.error('User fetch failed', { userId, error });
    // Custom Error mit spezifischem Type fÃ¼r bessere Error-Handling
    throw new UserFetchError(error);
  }
}

// âŒ BAD: Untypisiert, ohne Error-Handling
// Keine Types, String-Concatenation unsicher, kein Error-Handling
const getUserData = (id) => api.get('/users/' + id).data
```

### **Error-Handling:**
- **Jede API-Call** braucht try/catch + Sentry tracking
- **Custom Error Classes** fÃ¼r spezifische Fehlertypen
- **UI Error Boundaries** mit Retry-FunktionalitÃ¤t
- **Siehe CLAUDE_PATTERNS.md** fÃ¼r konkrete Implementation-Beispiele

---

## ğŸ“‹ **VERBINDLICHE STANDARDS**

### **ğŸš¨ KRITISCH: Alle Standards in STANDARDS.md sind PFLICHT**
- **GDPR/DSGVO Compliance** - Datenschutz von Anfang an
- **Security Standards** - Keine Kompromisse bei Sicherheit
- **Quality Standards** - Strategic test coverage of critical paths, TypeScript strict
- **Performance Standards** - Core Web Vitals einhalten
- **Accessibility Standards** - WCAG 2.1 AA Compliance

**â¡ï¸ Siehe STANDARDS.md fÃ¼r vollstÃ¤ndige Anforderungen**

### **ğŸ” STANDARDS-CHECK vor jedem Push:**
**VOR jedem git commit/push MUSS ich STANDARDS.md komplett durchgehen:**
- [ ] **GDPR-Check:** Alle neuen Features DSGVO-konform?
- [ ] **Security-Check:** Keine Vulnerabilities eingefÃ¼hrt?
- [ ] **Quality-Check:** Tests geschrieben, Coverage ausreichend?
- [ ] **Performance-Check:** Keine Regression in Core Web Vitals?
- [ ] **Accessibility-Check:** WCAG 2.1 AA eingehalten?

### **ğŸ”’ GDPR COMPLIANCE WORKFLOW (MANDATORY)**
**VOR Implementation JEDES Features mit User-Daten:**
1. **Legal Basis Check**: Hat dieses Feature proper legal basis? (STANDARDS.md Zeilen 12-17)
2. **Data Minimization**: Sammeln wir nur notwendige Daten? (STANDARDS.md Zeile 13)
3. **User Rights**: Kann User diese Daten exportieren/lÃ¶schen? (STANDARDS.md Zeilen 47-52)
4. **Consent Management**: Proper Opt-in/Opt-out implementiert? (STANDARDS.md Zeilen 20-45)

**ğŸ›‘ STOP REGEL**: Bei JEDER GDPR-Unsicherheit â†’ User fragen BEVOR Implementation!

**âš ï¸ WICHTIG:** Bei JEDER Unstimmigkeit oder Unsicherheit bezÃ¼glich STANDARDS.md:
**STOPPE sofort und informiere den User BEVOR weitergemacht wird!**

Beispiele fÃ¼r Standards-Konflikte die User-RÃ¼ckfrage erfordern:
- Datenschutz-Bedenken bei neuen Features
- Performance-Probleme durch neue Dependencies
- Security-Risiken durch API-Ã„nderungen
- Accessibility-Probleme durch UI-Ã„nderungen

---

## ğŸ§ª **TESTING-STRATEGIE**

### **Test-Pyramide & Monitoring:**
```
E2E Tests (Playwright)     â† Kritische User-Flows
Integration Tests (Jest)   â† API + DB Interactions  
Unit Tests (Jest)          â† Pure Functions
Error Monitoring (Sentry)  â† Production Error Tracking
```

### **Siehe CLAUDE_TESTING.md fÃ¼r:**
- Detaillierte Test-Implementation-Patterns
- Jest + React Testing Library Beispiele
- Playwright E2E Test-Strategien
- Coverage-Targets und Quality-Gates

---

## ğŸ“ **MODULARE DOKUMENTATION**

### **Smart Loading System:**
```bash
CLAUDE.md              â† Basis (immer laden)
CLAUDE_PATTERNS.md     â† Implementation-Patterns
CLAUDE_API.md         â† API-Integration Guidelines  
CLAUDE_TESTING.md     â† Testing-Strategies
CLAUDE_DEPLOYMENT.md  â† Production-Guidelines
```

**Loading-Regel:** Lade nur relevante Module fÃ¼r aktuellen Task.

---

## ğŸ­ **SLASH-COMMANDS**

```bash
/plan <feature>     â†’ Strukturierter Implementierungsplan mit Dependencies
/review            â†’ Code-Quality Check + Security-Review + Performance-Analyse  
/test <component>  â†’ Schreibe/aktualisiere Unit + Integration + E2E Tests
/debug <issue>     â†’ Systematische Problem-Analyse mit Root-Cause-Identification
/deploy           â†’ Production-Ready Checklist + Security + Performance Validation
```

---

## ğŸ“Š **SUCCESS-METRIKEN**

### **Development Quality:**
- Zero `any` types in final code
- Strategic Coverage of Business-Critical Areas (45-50%)
- < 5 ESLint warnings
- All features have Error Boundaries

---

## ğŸ”„ **ITERATION-CYCLE**

### **Feature-Development:**
1. **Plan** (5min) â†’ Implementation-Strategie
2. **Code** (45min) â†’ Feature + Tests
3. **Validate** (10min) â†’ Quality-Gates prÃ¼fen
4. **Ship** â†’ Commit + Docker restart

### **Bug-Fixing:**
1. **Reproduce** â†’ Minimal failing case
2. **Root-Cause** â†’ Warum ist es passiert?
3. **Fix** â†’ LÃ¶sung + Prevention
4. **Test** â†’ Regression-Test hinzufÃ¼gen

---

## ğŸ“‹ **ROADMAP INTEGRATION WORKFLOW**

### **âš ï¸ CRITICAL: Automatische Roadmap-Updates**
**BEI JEDER Implementation-Entscheidung die "Future Tasks" erzeugt:**

1. **SOFORT zur IMPLEMENTATION-ROADMAP.md hinzufÃ¼gen:**
   ```bash
   - Task X.Y: [Beschreibung der fehlenden Funktion]
     - X.Y.1: [Spezifische Implementation]
     - X.Y.2: [Tests schreiben]
     - X.Y.3: [Integration testen]
   ```

2. **TodoWrite tool verwenden:**
   - Task zu aktueller Session hinzufÃ¼gen
   - Priority setzen (high/medium/low)
   - Klare Success-Criteria definieren

3. **Beispiele fÃ¼r "Roadmap-pflichtige" Entscheidungen:**
   - Tests fÃ¼r noch nicht existierende Methoden entfernen
   - Placeholder-Implementierungen erstellen
   - "TODO" Kommentare hinzufÃ¼gen
   - Features temporary disablen
   - Mock-Implementierungen verwenden

### **ğŸ“ Standard-Format fÃ¼r Roadmap-Tasks:**
```markdown
- [ ] **Task X.Y: [Feature Name]**
  - [ ] X.Y.1: [Implementation Step 1]
  - [ ] X.Y.2: [Testing]
  - [ ] X.Y.3: [Documentation/Integration]
  - **Tools:** [Verwendete Tools/Libraries]
  - **Success Criteria:** [Messbare Ziele]
  - **Why Now/Later:** [BegrÃ¼ndung fÃ¼r Timing]
```

**âœ… REGEL:** Niemals "later" oder "TODO" ohne Roadmap-Entry!

---

**Version 2.0** - Optimiert fÃ¼r autonome Claude-Entwicklung  
*"Weniger Regeln, mehr Resultate"*