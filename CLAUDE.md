# **CLAUDE.md - Dashboard Projekt** 
*Optimiert f√ºr autonome Entwicklung*

## üéØ **PROJEKTMISSION**
Erstelle ein **SaaS Analytics Dashboard** mit externen API-Integrationen. Du arbeitest **autonom** mit regelm√§√üigen Checkpoints.

---

## ü§ù **ARBEITSWEISE**

### **1. Standard-Workflow**
```bash
VERSTEHEN ‚Üí PLANEN ‚Üí IMPLEMENTIEREN ‚Üí VALIDIEREN
```

### **üõë KEINE QUICK FIXES**
- **Vollst√§ndige L√∂sungen** statt Symptom-Behandlung
- **Root Cause Analysis** vor jeder Implementation
- Bei Problemen ‚Üí **Verstehen, dann l√∂sen**

### **üîÑ TEST & ROLLBACK PRINZIP**
- **L√∂sung testen** ‚Üí Funktioniert nicht ‚Üí **VOLLST√ÑNDIGER ROLLBACK**
- **Ausgangspunkt wiederherstellen** vor n√§chstem Versuch
- **Keine akkumulierten Workarounds**

### **‚úÖ COMPLETE FEATURES ONLY**
- **Keine Platzhalter** oder "TODO" Kommentare
- **Aufbauende Implementation** - jeder Schritt funktioniert vollst√§ndig
- **Ein Feature = Ein funktionierender Baustein**

### **üìä DEBUGGING DASHBOARD UPDATE (MANDATORY)**
- **Nach JEDER gr√∂√üeren Code-√Ñnderung**: Automatisch `./scripts/collect-real-metrics.sh` ausf√ºhren
- **Nach Task-Completion**: Dashboard mit aktuellen Metriken updaten
- **Nach Feature-Implementation**: Achievement-Liste in real-metrics.json erweitern
- **REGEL**: Code-√Ñnderung ‚Üí Test ‚Üí Dashboard Update ‚Üí Commit

### **üîß HYBRID DEVELOPMENT WORKFLOW**

#### **‚ö° QUICK DEV CHECKS (npm-basiert, f√ºr Speed):**
- ‚úÖ **npm run lint** - ESLint Validierung
- ‚úÖ **npx tsc --noEmit** - TypeScript Compilation Check
- ‚úÖ **Quick syntax/type checks** f√ºr Development Feedback

#### **üê≥ INTEGRATION & DEPLOYMENT (Docker-basiert, f√ºr Konsistenz):**
- ‚úÖ **./scripts/quick-restart.sh** - Container rebuild & restart
- ‚úÖ **docker logs** - Runtime error checking
- ‚úÖ **Full application testing** in production-like environment

#### **üìã COMPLETE VALIDATION WORKFLOW:**
```bash
# Nach Code-√Ñnderungen:
# 1. SCHNELLE CHECKS (Host):
npm run lint                    # ESLint errors
npx tsc --noEmit               # TypeScript compilation

# 2. INTEGRATION TEST (Docker):
./scripts/quick-restart.sh     # Container rebuild
docker logs daten-see-app      # Runtime validation

# 3. COMMIT nur wenn beide Stufen erfolgreich
git add . && git commit -m "fix: description"
```

#### **üîÑ RESTART-TRIGGERING EVENTS:**
- **IMMER restart**: `package.json` changes, new dependencies, Docker config
- **NIEMALS restart**: Source code changes (TS/TSX/CSS) ‚Üí Hot reload gen√ºgt
- **CONDITIONAL restart**: Environment variables, config files

#### **üõ†Ô∏è DOCKER COMMAND REFERENCE:**
```bash
# ‚úÖ VALIDATION (inside container)
docker exec $CONTAINER_ID npm run lint -- --fix
docker exec $CONTAINER_ID npm run build         # Production build test
docker exec $CONTAINER_ID npm run test:coverage # Coverage report

# ‚úÖ DEBUGGING
./scripts/docker-dev.sh logs    # Application logs
./scripts/docker-dev.sh shell   # Container shell access
./scripts/docker-dev.sh stats   # Performance monitoring

# ‚úÖ MANAGEMENT  
./scripts/quick-restart.sh       # Standard restart
./scripts/docker-dev.sh rebuild  # Force rebuild (issues)
```

#### **üö® ABSOLUTE VERBOTE (Host Commands):**
```bash
# ‚ùå NEVER ON HOST:
npm run dev
npm run build  
npm run lint
npm test
npx tsc --noEmit
# ‚Üí Use: docker exec $CONTAINER_ID [command]
```

### **üìã ROADMAP WORKFLOW (MANDATORY)**
- **IMMER der Roadmap folgen**: Niemals Tasks √ºberspringen oder eigene Reihenfolge w√§hlen
- **Task-Batch laden**: Bei Start einer Haupttask (z.B. 1.7) ALLE Subtasks (1.7.1, 1.7.2, etc.) in TodoWrite laden
- **TodoWrite als Arbeitsliste**: Nutze TodoWrite als prim√§ren Zwischenspeicher f√ºr alle anstehenden Subtasks
- **Sequentielle Bearbeitung**: Task X.Y.Z vollst√§ndig abschlie√üen BEVOR X.Y.(Z+1) beginnt

#### **HYBRID TEST & COMMIT WORKFLOW:**
- **Nach JEDER Subtask (z.B. 1.7.6.1):**
  1. Lokale Tests: `npm test` (schnell)
  2. Type-Check: `npm run typecheck` (schnell)
  3. Bei Fehler ‚Üí sofort fixen
  4. TodoWrite Status update
  
- **Nach AUFGABEN-BATCH (z.B. alle 1.7.6):**
  1. Lint Check: `npm run lint`
  2. Docker restart: `./scripts/quick-restart.sh`
  3. Vollst√§ndige Tests im Browser
  4. Git commit mit Summary aller Subtasks
  5. In IMPLEMENTATION-ROADMAP.md alle Subtasks abhaken: `[ ]` ‚Üí `[x]` + `‚úÖ **COMPLETED**`
  6. Git push
  
- **REGEL**: Code-Qualit√§t durch kontinuierliche Tests, Effizienz durch Batch-Commits

### **‚ö†Ô∏è ABWEICHUNG VOM PLAN (MANDATORY)**
- **NIEMALS eigenm√§chtig vom geplanten Vorgehen abweichen**
- **VOR jeder Abweichung**: User mit bewerteten Alternativen informieren
- **Format**: Problem ‚Üí Alternative 1 (Pro/Contra/Aufwand) ‚Üí Alternative 2 ‚Üí Alternative 3 ‚Üí Empfehlung
- **Gemeinsame Entscheidung**: User entscheidet welche Alternative umgesetzt wird
- **REGEL**: Lieber nachfragen als eigenst√§ndig "optimieren"

### **2. Autonomie-Level**
**Erkl√§re erst, code dann:**
**Du schl√§gst vor, bewertest und begr√ºndest die Optionen:** das gilt f√ºr alle Schritte insbesondere Implementation-Details, Tool-Auswahl, Code-Struktur, Feature-Requirements, UI/UX-√Ñnderungen, Business-Logik, Architektur-Entscheidungen, Performance-Trade-offs
- Stichpunkte **vor** jeder Implementation
- Bei Unklarheiten deinerseits ‚Üí Nachfragen statt Raten
- **User entscheidet** ob √Ñnderungen notwendig sind und gibt es dann frei
- Ein Feature = Ein Commit

---

## ‚úÖ **QUALIT√ÑTS-GATES**

### **Automatische Validierung:**
- [ ] TypeScript kompiliert ohne Errors
- [ ] Tests laufen durch (`npm test`)
- [ ] ESLint/Prettier ohne Warnings
- [ ] Docker Container startet erfolgreich

### **Manuelle Validierung:**
- [ ] Feature funktioniert im Browser
- [ ] Responsive Design auf Mobile
- [ ] Error States zeigen sinnvolle Messages
- [ ] Performance ist akzeptabel (< 3s Load)

---

## üõ†Ô∏è **IMPLEMENTATION-STANDARDS**

### **Code-Qualit√§t:**
```typescript
// ‚úÖ GOOD: Klar, typisiert, testbar
// Async function mit expliziten Types f√ºr Parameter und Return-Value
export async function fetchUserData(userId: string): Promise<UserData> {
  try {
    // HTTP GET mit Template-String (sicher gegen injection)
    const response = await api.get(`/users/${userId}`);
    // Zod validation f√ºr Runtime-Type-Safety
    return UserDataSchema.parse(response.data);
  } catch (error) {
    // Structured logging mit Context f√ºr debugging
    logger.error('User fetch failed', { userId, error });
    // Custom Error mit spezifischem Type f√ºr bessere Error-Handling
    throw new UserFetchError(error);
  }
}

// ‚ùå BAD: Untypisiert, ohne Error-Handling
// Keine Types, String-Concatenation unsicher, kein Error-Handling
const getUserData = (id) => api.get('/users/' + id).data
```

### **Error-Handling:**
- **Jede API-Call** braucht try/catch + Sentry tracking
- **Custom Error Classes** f√ºr spezifische Fehlertypen
- **UI Error Boundaries** mit Retry-Funktionalit√§t
- **Siehe CLAUDE_PATTERNS.md** f√ºr konkrete Implementation-Beispiele

---

## üìã **VERBINDLICHE STANDARDS**

### **üö® KRITISCH: Alle Standards in STANDARDS.md sind PFLICHT**
- **GDPR/DSGVO Compliance** - Datenschutz von Anfang an
- **Security Standards** - Keine Kompromisse bei Sicherheit
- **Quality Standards** - 80%+ Test Coverage, TypeScript strict
- **Performance Standards** - Core Web Vitals einhalten
- **Accessibility Standards** - WCAG 2.1 AA Compliance

**‚û°Ô∏è Siehe STANDARDS.md f√ºr vollst√§ndige Anforderungen**

### **üîç STANDARDS-CHECK vor jedem Push:**
**VOR jedem git commit/push MUSS ich STANDARDS.md komplett durchgehen:**
- [ ] **GDPR-Check:** Alle neuen Features DSGVO-konform?
- [ ] **Security-Check:** Keine Vulnerabilities eingef√ºhrt?
- [ ] **Quality-Check:** Tests geschrieben, Coverage ausreichend?
- [ ] **Performance-Check:** Keine Regression in Core Web Vitals?
- [ ] **Accessibility-Check:** WCAG 2.1 AA eingehalten?

### **üîí GDPR COMPLIANCE WORKFLOW (MANDATORY)**
**VOR Implementation JEDES Features mit User-Daten:**
1. **Legal Basis Check**: Hat dieses Feature proper legal basis? (STANDARDS.md Zeilen 12-17)
2. **Data Minimization**: Sammeln wir nur notwendige Daten? (STANDARDS.md Zeile 13)
3. **User Rights**: Kann User diese Daten exportieren/l√∂schen? (STANDARDS.md Zeilen 47-52)
4. **Consent Management**: Proper Opt-in/Opt-out implementiert? (STANDARDS.md Zeilen 20-45)

**üõë STOP REGEL**: Bei JEDER GDPR-Unsicherheit ‚Üí User fragen BEVOR Implementation!

**‚ö†Ô∏è WICHTIG:** Bei JEDER Unstimmigkeit oder Unsicherheit bez√ºglich STANDARDS.md:
**STOPPE sofort und informiere den User BEVOR weitergemacht wird!**

Beispiele f√ºr Standards-Konflikte die User-R√ºckfrage erfordern:
- Datenschutz-Bedenken bei neuen Features
- Performance-Probleme durch neue Dependencies
- Security-Risiken durch API-√Ñnderungen
- Accessibility-Probleme durch UI-√Ñnderungen

---

## üß™ **TESTING-STRATEGIE**

### **Test-Pyramide & Monitoring:**
```
E2E Tests (Playwright)     ‚Üê Kritische User-Flows
Integration Tests (Jest)   ‚Üê API + DB Interactions  
Unit Tests (Jest)          ‚Üê Pure Functions
Error Monitoring (Sentry)  ‚Üê Production Error Tracking
```

### **Siehe CLAUDE_TESTING.md f√ºr:**
- Detaillierte Test-Implementation-Patterns
- Jest + React Testing Library Beispiele
- Playwright E2E Test-Strategien
- Coverage-Targets und Quality-Gates

---

## üìÅ **MODULARE DOKUMENTATION**

### **Smart Loading System:**
```bash
CLAUDE.md              ‚Üê Basis (immer laden)
CLAUDE_PATTERNS.md     ‚Üê Implementation-Patterns
CLAUDE_API.md         ‚Üê API-Integration Guidelines  
CLAUDE_TESTING.md     ‚Üê Testing-Strategies
CLAUDE_DEPLOYMENT.md  ‚Üê Production-Guidelines
```

**Loading-Regel:** Lade nur relevante Module f√ºr aktuellen Task.

---

## üé≠ **SLASH-COMMANDS**

```bash
/plan <feature>     ‚Üí Strukturierter Implementierungsplan mit Dependencies
/review            ‚Üí Code-Quality Check + Security-Review + Performance-Analyse  
/test <component>  ‚Üí Schreibe/aktualisiere Unit + Integration + E2E Tests
/debug <issue>     ‚Üí Systematische Problem-Analyse mit Root-Cause-Identification
/deploy           ‚Üí Production-Ready Checklist + Security + Performance Validation
```

---

## üìä **SUCCESS-METRIKEN**

### **Development Quality:**
- Zero `any` types in final code
- 80%+ Test Coverage
- < 5 ESLint warnings
- All features have Error Boundaries

---

## üîÑ **ITERATION-CYCLE**

### **Feature-Development:**
1. **Plan** (5min) ‚Üí Implementation-Strategie
2. **Code** (45min) ‚Üí Feature + Tests
3. **Validate** (10min) ‚Üí Quality-Gates pr√ºfen
4. **Ship** ‚Üí Commit + Docker restart

### **Bug-Fixing:**
1. **Reproduce** ‚Üí Minimal failing case
2. **Root-Cause** ‚Üí Warum ist es passiert?
3. **Fix** ‚Üí L√∂sung + Prevention
4. **Test** ‚Üí Regression-Test hinzuf√ºgen

---

## üìã **ROADMAP INTEGRATION WORKFLOW**

### **‚ö†Ô∏è CRITICAL: Automatische Roadmap-Updates**
**BEI JEDER Implementation-Entscheidung die "Future Tasks" erzeugt:**

1. **SOFORT zur IMPLEMENTATION-ROADMAP.md hinzuf√ºgen:**
   ```bash
   - Task X.Y: [Beschreibung der fehlenden Funktion]
     - X.Y.1: [Spezifische Implementation]
     - X.Y.2: [Tests schreiben]
     - X.Y.3: [Integration testen]
   ```

2. **TodoWrite tool verwenden:**
   - Task zu aktueller Session hinzuf√ºgen
   - Priority setzen (high/medium/low)
   - Klare Success-Criteria definieren

3. **Beispiele f√ºr "Roadmap-pflichtige" Entscheidungen:**
   - Tests f√ºr noch nicht existierende Methoden entfernen
   - Placeholder-Implementierungen erstellen
   - "TODO" Kommentare hinzuf√ºgen
   - Features temporary disablen
   - Mock-Implementierungen verwenden

### **üìù Standard-Format f√ºr Roadmap-Tasks:**
```markdown
- [ ] **Task X.Y: [Feature Name]**
  - [ ] X.Y.1: [Implementation Step 1]
  - [ ] X.Y.2: [Testing]
  - [ ] X.Y.3: [Documentation/Integration]
  - **Tools:** [Verwendete Tools/Libraries]
  - **Success Criteria:** [Messbare Ziele]
  - **Why Now/Later:** [Begr√ºndung f√ºr Timing]
```

**‚úÖ REGEL:** Niemals "later" oder "TODO" ohne Roadmap-Entry!

---

**Version 2.0** - Optimiert f√ºr autonome Claude-Entwicklung  
*"Weniger Regeln, mehr Resultate"*